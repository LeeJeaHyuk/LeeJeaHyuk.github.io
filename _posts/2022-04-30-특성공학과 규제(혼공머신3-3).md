---
layout: single
title: "특성 공학과 규제"
categories: [hongong]
tag : [hongong,info]
---


# 특성 공학과 규제

혼자 공부하는 머신러닝 3-3

## 다중회귀

여러 개의 특성을 사용한 선형 회귀

![image-20220430190849221](../../images/2022-04-30-특성공학과 규제(혼공머신3-3)/image-20220430190849221.png)
$$
타깃 = a*특성1 + b*특성2+절편
$$
 

###  [Fish Market](https://www.kaggle.com/aungpyaeap/fish-market)의 농어 데이터를 이용한 다중 회귀

Fish Market Data에서 농어 데이터만 추출하여 농어의 무게를 나머지 특성으로 다중 회귀를 시도

```python
df.Perch = df[(df['Species']=='Perch')]
y=df['Weight']
X=df.drop(['Species','Weight'] ,axis=1)
```

기존의 데이터에서 농어만 추출하고 y에는 타깃 데이터 x에는 나머지 특성을 배치

```python
from sklearn.model_selection import train_test_split
train_input,  test_input, train_target, test_target = train_test_split(X, y, test_size=0.3, random_state=42)
```

 그 다음 테스트 세트를 30퍼센트로 데이터를 나누어 주었다. 

### PolynomialFeatures 를 사용하여 다항식 features로 변환

``` python
from sklearn.preprocessing import PolynomialFeatures

poly_features = PolynomialFeatures(degree=5, include_bias=False)
poly_features.fit(train_input)

train_poly = poly_features.transform(train_input)
test_poly = poly_features.transform(test_input)
```

degree를 통해 n차 다항식의 특성을 추가할 수 있었는데 이후 LinearRegression에서의 score가 degree가 높아질수록 현저히 작아지는 것을 보인다.

![111](../../images/2022-04-30-특성공학과 규제(혼공머신3-3)/111.png)

위에서부터 degree가 각 1, 2, 3, 4, 5의 경우

아마 이미 5개의 특성을 사용하기 때문에 다항식을 높일 경우 overfit되는 것이 아닐까라고 추측했다.

가장 높은 점수를 달성한 2차 다항식에서 특성의 개수를 살펴 보면 20개임을 알 수 있다.

![image-20220430204244186](../../images/2022-04-30-특성공학과 규제(혼공머신3-3)/image-20220430204244186.png)









![image-20220430201245104](../../images/2022-04-30-특성공학과 규제(혼공머신3-3)/image-20220430201245104.png)







## 릿지 회귀

## 라쏘 회귀

