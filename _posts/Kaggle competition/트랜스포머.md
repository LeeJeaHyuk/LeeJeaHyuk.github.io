# Transformer

[Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)

기존 인코더 / 디코더를 발전시키면서 RNN을 사용하지 않는 모델

학습 속도가 빠르면서 좋은 결과를 냄



Parallelization

병렬화 (일을 최대한 한번에 처리함)



RNN based encoder decoder with attention

고정된 문맥 벡터를 사용하지 않고 인코더에서 각 단어의 상태값을 계산한다

동적으로 인코더를 사용하기 때문에 긴 문장의 번역의 성능을 강화



attention만으로도 입력 데이터에서 중요한 정보들을 찾아내기





