---
layout: single
title: "순환 신경망 RNN"
categories: [hongong]
tag : [hongong,info]
---

## IMDB 리뷰 데이터셋

Internet Movie Database

imdb.com에서 수집한 리뷰를 감상평에 따라 긍정과 부정으로 분류해 놓은 데이터셋

50 ,000개의 샘플로이루어져 있고 훈련 데이터와 테스트 데이터에 각각 25,000개씩 나누어져 있다.

리뷰가 영화를 좋게 / 나쁘게 평가하는지 분류하는 모델을 만들어보자(감성, 감정 분석)

 

#### 자연어 처리 

NLP Natural language processing

컴퓨터를 사용해 인간의 언어를 처리하는 분야이다. 음성 인식 기계 번역 감성 분석 등이 있다.

자연어 처리 분야에서 훈련 데이터를 종종 말뭉치(corpus)라고 부른다. ex) IMDB 데이터셋 : 말뭉치

#### 토큰

텍스트를 숫자 데이터로 바꿀 때는 문장에서 각각의 단어에 정수를 매핑하는데 

일반적으로 영어 문장에서는 모두 소문자로 바꾸고 구둣점을 삭제한 다음 공백을 기준으로 분리한다.

이렇게 분리된 단어를 토큰이라고 부른다.

하나의 샘플은 여러 개의 토큰으로 이루어져 있고 1개의 토큰이 하나의 타임스탬프에 해당한다.

#### 어휘 사전 

훈련 세트에서 고유한 단어를 뽑아 만든 목록



## 케라스로 IMDB 불러오기

```python
from tensorflow.keras.datasets import imdb

(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words=500)
# 어휘사전의 단어를 가장 많이 사용하는 단어 500개만 사용하기

print(train_input.shape, test_input.shape)
#(25000,) (25000,)

print(len(train_input[0]))
#218
print(train_input[0])
#[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, ..., 16, 2, 19, 178, 32] #train data를 확인해보면 토큰이 정수값으로 바뀌어있는 것을 확인할 수 있다.
#input값 맨 처음의 예약된 정수 1은 샘플의 시작 부분의 토큰이다.
#두 번째로 예약된 정수인 2는 500개의 어휘사전에 포함되지 않은 단어들이다. 

#input data는 파이썬 리스트를 묶은 넘파이 배열이다. 각각의 리뷰(샘플)마다 길이가 다르기 때문에(numpy배열은 길이가 다른 데이터를 표현하지 못함)
print(train_target[:20])
#[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]
#이진 분류 긍정:1 부정:0
```











## 참고

박해선,혼자 공부하는 머신러닝, 한빛미디어, 2021,500~525p

[자연어 처리 위키](https://ko.wikipedia.org/wiki/%EC%9E%90%EC%97%B0%EC%96%B4_%EC%B2%98%EB%A6%AC)