## 순차 데이터

순서가 의미 있는 데이터 

ex) 텍스트 데이터,시계열 데이터



## 순환 신경망

7,8장에서 배운 완전 연결 신경망이나 합성곱 신경망은 이런 순서를 기억하지 않는다. 

하나의 샘플을 사용해서 정방향 계산을 수행하고 나면 그 샘플은 버려지고 다음 샘플을 처리할 때 재사용하지 않는다. 

이렇게 입력 데이터의 흐름이 앞으로만 전달되는 신경망을 피드포워드 신경망(feedforward neural network)이라고 한다. 





![순환 신경망 9-1](../../images/2022-06-11-순차 데이터와 순환 신경망(혼공머신9-1)/순환 신경망 9-1.png)



순환 신경망은(recurrent neural network, RNN)은 일반적은 완전 연결 신경망과 비슷한데 순환되는 고리가 완전 연결 신경망에 추가된 형태이다.

사진을 보면 A, B, C 각각의 샘플이 각 타입스텝 마다 순환층에 들어오는데 그 출력이 계속해서 누적된다는 것을 보여준다.

A샘플의 출력 $O_A$가 B샘플의 타입스텝 때 같이 들어온다. 그 출력 $O_B$는 $O_A$와도 연관이 있을 것이다. C샘플의 타입스탭때도 마찬가지로 진행된다.

순환층을 보통 셀(CELL)이라고 부르고 셀의 출력값을 은닉 상태(hidden state)라고 한다. (은닉층에서 출력되는 값)

RNN에서 활성화 함수는 보통  $tanh$함수를 사용한다.



|      신경망       |    출력     |
| :---------------: | :---------: |
| 완전 연결 신경망  | 활성화 출력 |
| 합성곱 신경망 CNN |   특성 맵   |
|  순환 신경망 RNN  |  은닉 상태  |



## 타임스텝으로 펼친 신경망

![image-20220612182349305](../../images/2022-06-11-순차 데이터와 순환 신경망(혼공머신9-1)/image-20220612182349305.png)

 

왼쪽은  순환 신경망을 표현하는 그림이다 입력과 곱해지는 가중치 $w_x$와 이전 타입스텝의 은닉 상태와 곱해지는 가중치 $w_h$가 있다.

순환 신경망의 그림을 각 타입스텝마다 따로 그리면 "타임스텝으로 펼친다" 라는 표현을 사용한다.

오른쪽 그림은 타입스텝으로 펼친 순환 신경망으로 $w_h$의 가중치가 변하는 모습을 더 자세하게 나타낸다.



타입스텝의 과정을 살펴보면 타입스텝1에서 초기의 은닉상태 $h_0$의 값은 0이고 은닉상태 $h_1$값을 알아낼 수 있다.

은닉상태$h_1$값은 타입스텝2에서  $w_h$와 곱해지고 은닉상태$h_2$값을 구하고 같은 방식으로 타입스텝3에서는 $h_3$값을 구하게 된다.

이렇게 주어진 샘플의 길이에 맞게 진행된다.

이 때 가중치 $w_h,w_x$은 샘플마다 동일하게 사용된다. (타입스텝에 따라서 가중치를 공유한다.)

그러므로 모델 파라미터의 수가 줄게 된다.



## 순환 신경망의 가중치

