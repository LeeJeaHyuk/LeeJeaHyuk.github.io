---
layout: single
title: "순환 신경망 RNN"
categories: [hongong]
tag : [hongong,info]
toc : true
---

## 순차 데이터

순서가 의미 있는 데이터 

ex) 텍스트 데이터,시계열 데이터



## 순환 신경망

7,8장에서 배운 완전 연결 신경망이나 합성곱 신경망은 이런 순서를 기억하지 않는다. 

하나의 샘플을 사용해서 정방향 계산을 수행하고 나면 그 샘플은 버려지고 다음 샘플을 처리할 때 재사용하지 않는다. 

이렇게 입력 데이터의 흐름이 앞으로만 전달되는 신경망을 피드포워드 신경망(feedforward neural network)이라고 한다. 





![순환 신경망 9-1](../../images/2022-06-11-순차 데이터와 순환 신경망(혼공머신9-1)/순환 신경망 9-1.png)



순환 신경망은(recurrent neural network, RNN)은 일반적은 완전 연결 신경망과 비슷한데 순환되는 고리가 완전 연결 신경망에 추가된 형태이다.

사진을 보면 A, B, C 각각의 샘플이 각 타입스텝 마다 순환층에 들어오는데 그 출력이 계속해서 누적된다는 것을 보여준다.

A샘플의 출력 $O_A$가 B샘플의 타입스텝 때 같이 들어온다. 그 출력 $O_B$는 $O_A$와도 연관이 있을 것이다. C샘플의 타입스탭때도 마찬가지로 진행된다.

순환층을 보통 셀(CELL)이라고 부르고 셀의 출력값을 은닉 상태(hidden state)라고 한다. (은닉층에서 출력되는 값)

RNN에서 활성화 함수는 보통  $tanh$함수를 사용한다.



|      신경망       |    출력     |
| :---------------: | :---------: |
| 완전 연결 신경망  | 활성화 출력 |
| 합성곱 신경망 CNN |   특성 맵   |
|  순환 신경망 RNN  |  은닉 상태  |



## 타임스텝으로 펼친 신경망

![image-20220612182349305](../../images/2022-06-11-순차 데이터와 순환 신경망(혼공머신9-1)/image-20220612182349305.png)

 

왼쪽은  순환 신경망을 표현하는 그림이다 입력과 곱해지는 가중치 $w_x$와 이전 타입스텝의 은닉 상태와 곱해지는 가중치 $w_h$가 있다.

순환 신경망의 그림을 각 타입스텝마다 따로 그리면 "타임스텝으로 펼친다" 라는 표현을 사용한다.

오른쪽 그림은 타입스텝으로 펼친 순환 신경망으로 $w_h$의 가중치가 변하는 모습을 더 자세하게 나타낸다.



타입스텝의 과정을 살펴보면 타입스텝1에서 초기의 은닉상태 $h_0$의 값은 0이고 은닉상태 $h_1$값을 알아낼 수 있다.

은닉상태$h_1$값은 타입스텝2에서  $w_h$와 곱해지고 은닉상태$h_2$값을 구하고 같은 방식으로 타입스텝3에서는 $h_3$값을 구하게 된다.

이렇게 주어진 샘플의 길이에 맞게 진행된다.

이 때 가중치 $w_h,w_x$은 샘플마다 동일하게 사용된다. (타입스텝에 따라서 가중치를 공유한다.)

그러므로 모델 파라미터의 수가 줄게 된다.

 

## 순환 신경망의 가중치

![순환 신경망의 가중치](../../images/2022-06-11-순차 데이터와 순환 신경망(혼공머신9-1)/순환 신경망의 가중치.png) 

순환 신경망의 가중치의 개수를 살펴보면 

입력층과는 완전 연결되기 때문에 입력층이 4개 순환층이 3개라고 가정하면 12개인것은 명확하다

하지만 순환층에서는 은닉상태가 다시 곱해지는데 이 때 자기 뉴런에게만 곱해지는 것이 아니라 전체 다른 뉴런에 완전 연결된다. 



순환 신경망 3개가 완전 연결된 모습을 완전 연결한다고 생각하면 다음과 같다.

![image-20220617205019736](../../images/2022-06-11-순차 데이터와 순환 신경망(혼공머신9-1)/image-20220617205019736.png)



그러므로 모델 파라미터 개수 p는 다음과 같다.

b:절편
$$
p=w_x+w_h+b
\\
p=12+9+3=24
$$




## 순환 신경망의 입력

![image-20220617210011144](../../images/2022-06-11-순차 데이터와 순환 신경망(혼공머신9-1)/image-20220617210011144.png)

단어 데이터를 예시로 살펴보자

I am a boy라는 단어(토큰)이 있다. 각 단어를 3개의 벡터로 표현한다고 가정하면 타입스텝은 총 4번이다

 각각 단어마다 3개의 벡터로 이루어져 있기 때문에 3번째 차원은 3이 되고

샘플(문장)이 1개이기 때문에 배치 차원은 1이 된다.



그림으로 보면

![image-20220617210653288](../../images/2022-06-11-순차 데이터와 순환 신경망(혼공머신9-1)/image-20220617210653288.png)

(샘플, 타입스텝 크기, 단어 표현/몇 개의 벡터로 표기하는지)

3차원 배열이 순환층을 통과하게 되면 순환층에 있는 뉴런의 개수만큼 출력이 만들어져서 2차원 배열이 구성된다. 



3차원 배열의 출력이 2차원으로 줄였다는 것은 타입스텝의 정보가 사라졌다는 것을 의미한다.



![image-20220617211749072](../../images/2022-06-11-순차 데이터와 순환 신경망(혼공머신9-1)/image-20220617211749072.png)

이는 순환신경망의 은닉상태는 마지막 타입스텝의 은닉상태만 출력하기 때문이다. 



## 다층 순환 신경망

 하지만 다층 순환 신경망에서는 3차원 배열을 출력한다.

![image-20220617211317314](../../images/2022-06-11-순차 데이터와 순환 신경망(혼공머신9-1)/image-20220617211317314.png)

마지막 타입스텝의 은닉 상태는 똑같이 출력되지만

다음 셀에 3차원 배열을 전달하기 위해서 이전 셀은 모든 타입스텝의 은닉 상태를 출력한다. 

다층 순환 신경망에서 출력되는 3차원 배열은 첫 입력의 3차원 배열과는 다른데

![image-20220617213303236](../../images/2022-06-11-순차 데이터와 순환 신경망(혼공머신9-1)/image-20220617213303236.png)

첫 번쨰 입력에서는 단어 표현(몇 개의 벡터로 표현하는지)이지만 다층 훈련 신경망에서 다음 셀에 전달되는 3차원 배열에는 이전 층의 뉴런 개수가 전달된다.



## 순환 신경망을 사용한 예측



![image-20220617214003518](../../images/2022-06-11-순차 데이터와 순환 신경망(혼공머신9-1)/image-20220617214003518.png)



20개의 타임스텝을 사용하고 단어를 100개의 벡터로 표현했다.

셀이 10개이므로 (10,)으로 출력되었고

샘플마다 셀이 1차원 배열을 출력하기 때문에 합성곱 신경망처럼 flatten  클래스로 펼칠 필요가 없이 바로 출력층과 연결한다.

분류일 경우 분류하기 위한 클래스의 개수만큼 뉴런을 만들고 다중/이중 분류이면  소프트맥스/시그모이드를 통해 예측한다.



## 참고

박해선,혼자 공부하는 머신러닝, 한빛미디어, 2021,486~497p
