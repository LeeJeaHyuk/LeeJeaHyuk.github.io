# 인공 신경망

### 패션 MNIST

karas에 내장되어있는 패션 MNIST 데이터를 사용

10개의 클래스와 6만개의 $ 28\times 28 $ 흑백 데이터 샘플로 이루어져 있다.



## 로지스틱 회귀

```python
from tensorflow import keras

(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()
# 훈련과 테스트 데이터의 입력과 타겟쌍을 반환하기

print(train_input.shape, train_target.shape)
# (60000, 28, 28) (60000,) 28x28 이미지 데이터가 6만개 존재

print(test_input.shape, test_target.shape)
# (10000, 28, 28) (10000,) 테스트데이터는 만개 존재
```



### 입력과 타겟 샘플

```python
import matplotlib.pyplot as plt

fig, axs = plt.subplots(1, 10, figsize=(10,10))
for i in range(10):
    axs[i].imshow(train_input[i], cmap='gray_r')    
    # 값이 높아야 계산하기 편하기 때문에 반전해준 모습(배경이 검은색으로 보이기 때문에)
    axs[i].axis('off')
plt.show()
```





```python
print([train_target[i] for i in range(10)])
#[9, 0, 0, 3, 0, 2, 7, 2, 5, 5] 타겟 데이터 0~9 정수값

import numpy as np

print(np.unique(train_target, return_counts=True))
# return_counts=True로 하면 클래스 정수값이 어떤 게 들어가 있는지, 각각 정수값이 얼마만큼 들어가 있는지 세준다.
(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000]))
#클래스마다 6000개씩 고르게 들어가있다. (예제 데이터이므로)
```



## 로지스틱 회귀로 패션 아이템 분류하기

```python
train_scaled = train_input / 255.0 # 픽셀값이 0~255이므로 255로 나누어주면 0~1로 표준화되는 효과가 있다.
train_scaled = train_scaled.reshape(-1, 28*28) #차원을 곲해서 하나의 차원으로 만들어주기위해서
print(train_scaled.shape) # 28x28 이미지를 펼쳐서 하나의 차원으로
#(60000, 784)

from sklearn.model_selection import cross_validate
from sklearn.linear_model import SGDClassifier

sc = SGDClassifier(loss='log', max_iter=5, random_state=42)
# 로지스틱 함수를 바로 쓰지않고 경사하강법(SGD)에서 loss함수를 log로 지정

scores = cross_validate(sc, train_scaled, train_target, n_jobs=-1)
print(np.mean(scores['test_score']))
# 0.8195666666666668 훈련 데이터의 cross_validate의 교차검증점수의 평균값
# test_score이지만 훈련 데이터로 만든 검증 데이터이다.
```



#### 로지스틱 손실함수

10개의 클래스를 다중 분류를 하는데 SGD에 크로스엔트로피 손실함수를 지정할수는 없기 때문에 로지스틱 손실함수를 지정하는데 로지스틱 손실함수는 클래스만큼의 이진분류를 시행한 후에 소프트맥스를 사용하는 식으로 해결한다.

OVA

OVR



## 인공 신경망과 로지스틱 회귀

출력층이 한개만 존재하는 가장 간단한 인공 신경망은 경사하강법을 사용한 로지스틱 회귀나 선형 회귀 모델과 구분할 수 없다

출력층 마지막 클래스들의 확률을 출력하는 층

입력층 입력데이터가 놓여있는 층

유닛,뉴런 : 값을 알기를 원하는 클래스들

절편값은 유닛과 뉴런에 항상 더해지는데 생략되는 경우가 많다.



## 케라스 모델

```
```





















## 인공 신경망

```python
import tensorflow as tf
from tensorflow import keras

from sklearn.model_selection import train_test_split

train_scaled, val_scaled, train_target, val_target = train_test_split(
    train_scaled, train_target, test_size=0.2, random_state=42)
print(train_scaled.shape, train_target.shape)
#(48000, 784) (48000,)
print(val_scaled.shape, val_target.shape)
#(12000, 784) (12000,)
dense = keras.layers.Dense(10, activation='softmax', input_shape=(784,))
model = keras.Sequential(dense)

```



## 인공 신경망으로 패션 아이템 분류하기

```python
model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')
print(train_target[:10])
#[7 3 5 8 6 9 3 3 9 9]

model.fit(train_scaled, train_target, epochs=5)
model.evaluate(val_scaled, val_target)
```

