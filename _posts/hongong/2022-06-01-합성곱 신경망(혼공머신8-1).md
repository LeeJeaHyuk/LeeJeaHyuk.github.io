---
layout: single
title: "합성곱 신경망 CNN"
categories: [hongong]
tag : [hongong,info]
toc : true
---

# 합성곱 신경망의 구성 요소

CNN

Convolutional Neural Network



## 합성곱 신경망 왜?

합성곱 신경망을 사용하는 이

![kisspng-convolutional-neural-network-deep-learning-artific-5ae77e44016ed8.9429587815251205800059](../../images/2022-06-01-합성곱 신경망(혼공머신8-1)/kisspng-convolutional-neural-network-deep-learning-artific-5ae77e44016ed8.9429587815251205800059.png)

2차원 이미지를 훈련하는 데 1차원으로 펼쳐서 신경망을 사용한다면 2차원의 이미지의 특성을 반영한다고 할 수 없다.

이러한 문제는 이미지를 분류하는데에서 이미지의 특성을 찾아내지 못하고 overfitting 되는 문제로 이어진다.

하지만 합성곱 신경망은 2차원 이미지의 차원을 유지하면서 훈련함으로써 임의의 픽셀의 주변 맥락을 반영함으로써 문제를 보완한다.



## 합성곱 신경망 원리

기존 신경망에서 밀집층에는 뉴런마다 입력 개수만큼 가중치가 있고 모든 입력에 가중치를 곱한다.

합성곱은 밀집층과 다르게 입력 데이터 전체에 가중치를 적용하는 것이 아니라 일부에 가중치를 곱한다. 

일종의 도장 역할을 하는 하이퍼파라미터인 필터(커널)을 정해주면 이 필터만이 모든 입력의 가중치가 되어서 필터의 개수만큼 입력과 곱해져서 출력(특성 맵)을 얻게 된다.



### 특성 맵의 크기 계산

$I_{h}$ : 입력의 높이
$I_{w}$ : 입력의 너비
$K_{h}$ : 커널의 높이
$K_{w}$ : 커널의 너비
$S$ : 스트라이드
$O_{h}$ : 특성 맵의 높이
$O_{w}$ : 특성 맵의 너비
$P$:패딩의 폭


$$
O_{h} = floor(\frac{I_{h} - K_{h}}{S}+1)
\\
O_{w} = floor(\frac{I_{w} - K_{w}}{S}+1)
\\
\\
O_{h} = floor(\frac{I_{h} - K_{h} + 2P}{S}+1)
\\
O_{w} = floor(\frac{I_{w} - K_{w} + 2P}{S}+1)
\\
$$


## 패딩

![패딩11](../../images/2022-06-01-합성곱 신경망(혼공머신8-1)/패딩11.png)

합성곱 신경망을 훈련하면 그림처럼 이미지 안쪽의 픽셀이 더 많이 계산되는 것을 볼 수 있는데(4:1) 오늘쪽처럼 픽셀을 더해 주는 패딩을 해주면 (9:4)로 비율이 완화된 것을 볼 수 있다.

또한 패딩을 사용하면 커널을 더 많이 곱해야 하기 때문에 특성맵을 키우기 위해 사용한다.



### 패딩 종류

패딩을 추가하지 않는 경우를 valid padding 이라고 한다. karas에서 기본값으로 설정되어 있다.

새로 추가되는 부분에 0을 넣어주면 zero padding이라고 한다.

입력데이터의 모든 원소가 같은 비율이 되도록 패딩하는 것을 full padding 이라고 한다.

입력 크기와 출력 크기를 동일하게 유지하고 싶으면 same padding 을 사용하면 된다.



### 스트라이드

지금까지 예시에는 커널이 기본적으로 1칸씩 이동하면서 특성 맵을 출력했지만 2칸씩 이동하는것도 충분이 생각해볼 수 있다.

1을 초과해서 사용하는 경우는 많이 없다.



## 풀링

특성 맵의 개수는 그대로 유지하면서 가로 세로 크기를 줄이는 역할을 한다.

![image-20220602182346897](../../images/2022-06-01-합성곱 신경망(혼공머신8-1)/image-20220602182346897.png)

합성곱은 입력층과 커널의 가중치와 곱하는 과정이지만 풀링은 합성곱과 유하하지만 가중치와 곱해지거나 하는 것이 아닌 단순히 특성 맵의 크기를 줄이는 것이다.

전형적으로 2x2 풀링으로 크기를 줄인다.

커널만큼의 체널 차원이 생기는데 이 체널 차원의 개수는 줄이지 않는다

최대 풀링은 가장 큰 값으로 대표하게 하는 것이고

평균 풀링은 평균낸 값으로 대표하게 하는 것이다.

풀링의 크기와 스트라이드의 크기는 동일하게 된다.

홀수의 경우 어떻게 하는가?



## 합성곱 신경망의 전체 구조

![image-20220605133002850](../../images/2022-06-01-합성곱 신경망(혼공머신8-1)/image-20220605133002850.png)

1. 입력에 패딩을 추가해서 4x4 -> 6x6 (패딩을 지정해 주면 적절한 크기를 알아서 추가해준다)
2. 3x3 필터(커널)를 3개 사용해서 특성 맵 3개를 얻었다. (각 필터마다 절편b가 존재한다.)
3. 각각 특성 맵 마다 활성화 함수를 적용한 후 합쳐서 차원이 증가된 4x4x3 특성 맵을 얻게 된다.
4. 2x2 풀링을 사용해서 특성맵의 크기를 줄인 모습니다.
5. 풀링이 완료되면 1차원 배열로 펼쳐서 은닉층, 출력층을 통과시켜 최종예측을 이끌어낸다.



## 3차원 합성곱

깊이(RGB체널) 이 존재하는 경우에 

![image-20220605134637860](../../images/2022-06-01-합성곱 신경망(혼공머신8-1)/image-20220605134637860.png)

1. 커널 또한 깊이만큼 만들어주면 된다. 위에서는 3차원이므로 3차원 배열로 만들어 주면 된다.
2. 입력층과 커널이 곱해지면 예시에서는 27개 입력 x 27개 커널 가중치 +b로 1개의 값이 출력되고 총 4회 진행되므로 2x2 특성 맵이 만들어지게 된다.
3. 또한 RGB체널이 없는 흑백 이미지이더라도 흑백 체널을 추가하여 3차원 배열로 계산한다.



### 여러 개의 필터가 있는 경우

![image-20220605135232390](../../images/2022-06-01-합성곱 신경망(혼공머신8-1)/image-20220605135232390.png)



## 케라스 합성곱

```python
from tenserflow import keras
keras.layers.Conv2D(10, kenel_size=(3,3), activation='relu', padding='same', strides=1)
# (필터 개수, 커널의 크기, 활성화함수, 패딩, 스트라이드)

keras.layers.MaxPooling2D(2) #풀링의 크기
keras.layers.MaxPooling2D(2, strides=2, padding='valid')
# 스트라이드는 따로 지정하지 않아도 풀링의 크기에 따라서 자동으로 지정된다.
# 입력특성의 크기를 줄이는 것이 목적이기 때문에 valid 패딩을 사용한다. 그러므로 지정할 필요 없다.

```



### 커널이 짝수인 경우

패딩할 때 나누어지지 않음

?





## 참고

[합성곱 크기](https://wikidocs.net/64066)

[커널 크기 짝수인 경우](https://www.koreascience.or.kr/article/JAKO201908071718621.pdf) 3p

박해선,혼자 공부하는 머신러닝, 한빛미디어, 2021,422~443p
