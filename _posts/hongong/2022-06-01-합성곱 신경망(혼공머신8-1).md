# 합성곱 신경망의 구성 요소



## 합성곱 신경망 왜?

![kisspng-convolutional-neural-network-deep-learning-artific-5ae77e44016ed8.9429587815251205800059](../../images/2022-06-01-합성곱 신경망(혼공머신8-1)/kisspng-convolutional-neural-network-deep-learning-artific-5ae77e44016ed8.9429587815251205800059.png)

2차원 이미지를 훈련하는 데 1차원으로 펼쳐서 신경망을 사용한다면 2차원의 이미지의 특성을 반영한다고 할 수 없다.

이러한 문제는 이미지를 분류하는데에서 이미지의 특성을 찾아내지 못하고 overfitting 되는 문제로 이어진다.

하지만 합성곱 신경망은 2차원 이미지의 차원을 유지하면서 훈련함으로써 임의의 픽셀의 주변 맥락을 반영함으로써 문제를 보완한다.



## 합성곱 신경망 원리

기존 신경망에서 밀집층에는 뉴런마다 입력 개수만큼 가중치가 있고 모든 입력에 가중치를 곱한다.

합성곱은 밀집층과 다르게 입력 데이터 전체에 가중치를 적용하는 것이 아니라 일부에 가중치를 곱한다. 

일종의 도장 역할을 하는 하이퍼파라미터인 필터(커널)을 정해주면 이 필터만이 모든 입력의 가중치가 되어서 필터의 개수만큼 입력과 곱해져서 출력(특성 맵)을 얻게 된다.



### 특성 맵의 크기 계산

$I_{h}$ : 입력의 높이
$I_{w}$ : 입력의 너비
$K_{h}$ : 커널의 높이
$K_{w}$ : 커널의 너비
$S$ : 스트라이드
$O_{h}$ : 특성 맵의 높이
$O_{w}$ : 특성 맵의 너비
$P$:패딩의 폭


$$
O_{h} = floor(\frac{I_{h} - K_{h}}{S}+1)
\\
O_{w} = floor(\frac{I_{w} - K_{w}}{S}+1)
\\
\\
O_{h} = floor(\frac{I_{h} - K_{h} + 2P}{S}+1)
\\
O_{w} = floor(\frac{I_{w} - K_{w} + 2P}{S}+1)
\\
$$


## 패딩

![패딩11](../../images/2022-06-01-합성곱 신경망(혼공머신8-1)/패딩11.png)

합성곱 신경망을 훈련하면 그림처럼 이미지 안쪽의 픽셀이 더 많이 계산되는 것을 볼 수 있는데(4:1) 오늘쪽처럼 픽셀을 더해 주는 패딩을 해주면 (9:4)로 비율이 완화된 것을 볼 수 있다.

또한 패딩을 사용하면 커널을 더 많이 곱해야 하기 때문에 특성맵을 키우기 위해 사용한다.





새로 추가되는 부분에 0을 넣어주면 제로 패딩이라고 한다.





## 케라스 합성곱



```python
from tenserflow import keras
keras.layers.Conv2D(10, kenel_size=(3,3), activation='relu', padding='same')
# (필터 개수, 커널의 크기, 활성화함수)
# 
```



### 커널이 짝수인 경우

패딩할 때 나누어지지 않음





## 참고

[합성곱 크기](https://wikidocs.net/64066)

[커널 크기 짝수인 경우](https://www.koreascience.or.kr/article/JAKO201908071718621.pdf) 3p
