# 차원과 차원 축소

6-2 kmeans를 공부할 때 사용한 이미지는 300장이었지만 실제 서비스를 진행한다면 이미지들을 계속해서 등록해야 할 것이므로 저장공간이 부족할 수 있다.

나중에 군집이나 분류에 영향을 끼치지 않으면서 업로드된 사진의 용량을 줄이는 방법



데이터가 가진 속성을 특성이라고 부를 수 있다. 과일 사진 한 장은 100x100 인 10000개의 픽셀을 가지고 있으므로 10000개의 특성을 가지고 있다고 할 수 있다.

머신러닝에서는 이런 특성을 차원이라고 부르는데 그렇다면 이 10000개의 차원을 줄일 수 있다면 저장공간을 절약할 수 있을 것이다.



## 차원 축소 알고리즘

3장에서 특성이 많으면 선형 모델의 성능이 높아지고 훈련 데이터에 쉽게 과대적합된다는 것을 배웠다.

차원 축소는  데이터를 가장 잘 나타내는 일부 특성을 선택하여 데이터 크기를 줄이고 지도학습 모델의 성능을 향상시킬 수 있는 방법이다.



## 주성분 분석 PCA

줄어든 차원에서 다시 원본 차원으로 손실을 최대한 줄이면서 복원할 수도 있다.

주성분 분석은 데이터에 있는 분산이 큰 방향을 찾는 것으로 이해할 수 있다. 분산 : 데이터가 퍼져있는 정도

주성분 분석은 분산이 큰 방향을 표현하는 벡터를 찾는 것



주성분 : 분산이 큰 방향을 표현하는 벡터



## PCA 클래스

[300개의 과일 데이터](https://bit.ly/fruits_300_data)를 사용해서 

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=50) #주성분을 50개만 찾도록 지정
pca.fit(fruits_2d)

print(pca.components_.shape) #components_ 에 주성분 데이터가 들어가 있다.
#'_'는 하이퍼파라미터가 아닌 학습된 데이터에 붙는다.(구분하기 위해)
#(50, 10000) 50개의 행과 10000개의 열로 이루어져 있다.

draw_fruits(pca.components_.reshape(-1, 100, 100))
#다시 100x100으로 reshape해서 주성분의 이미지를 그려볼 수 있다.

print(fruits_2d.shape)
#(300, 10000) 원래의 특성

fruits_pca = pca.transform(fruits_2d) 
print(fruits_pca.shape)
#(300, 50) transform은 10000개의 특성을 50개로 변환해준다.
#300개의 샘플이 각각 50개의 특성으로 줄어든 것 1/200만큼의 데이터 size가 줄어들었다.
```

![image-20220522130210728](../../images/2022-05-21-주성분 분석(혼공머신6-3)/image-20220522130210728.png)



## 원본 데이터 재구성

```python
fruits_inverse = pca.inverse_transform(fruits_pca)
print(fruits_inverse.shape)
#(300, 10000) 다시 특성이 300,10000으로 바뀜

fruits_reconstruct = fruits_inverse.reshape(-1, 100, 100) #이미지를 보기위해 reshape
for start in [0, 100, 200]:
    draw_fruits(fruits_reconstruct[start:start+100])
    print("\n")
```



![image-20220522133205518](../../images/2022-05-21-주성분 분석(혼공머신6-3)/image-20220522133205518.png)



![image-20220522133220027](../../images/2022-05-21-주성분 분석(혼공머신6-3)/image-20220522133220027.png)



![image-20220522133231419](../../images/2022-05-21-주성분 분석(혼공머신6-3)/image-20220522133231419.png)



1/200만큼 줄어들었지만 구분할 수 있을 정도로 재구성이 된 것을 볼 수 있다.



## 설명된 분산

```python
print(np.sum(pca.explained_variance_ratio_))
#0.9215808173798626 원래 훈련 데이터의 92%만큼의 분산을 보존하고 있다.
#각 주성분 50개가 얼마만큼 분산을 잘 유지했는지 알려주는 값

plt.plot(pca.explained_variance_ratio_)
```

![image-20220522133902664](../../images/2022-05-21-주성분 분석(혼공머신6-3)/image-20220522133902664.png)



## 다
